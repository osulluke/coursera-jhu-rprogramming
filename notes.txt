Week 1:

	- http://swirlstats.com/ cool site that will show you how to use R, using R...this will install a swirl package that then will install interactive courses in R! Nice!

	- Ok, working directory set, but does it make sense yet, to have a separate code folder, and maybe a separate data folder? Or maybe the answer is to have separate folders for each of the projects that will be worked on.

	(part 2)

	- What is R? It's a dialect of S...an early version of a FORTRAN set of libraries done for statistics. Then reimplemented in C...made it more portable...duh...resembles version 3. Version 4/5 is what most resembles what we have today. Originally developed by AT&T Bell labs.

	- Created in 1991 in New Zealand. R is modular...doesn't require a huge software package. Very useful as an interactive tool (eases transition from user to programmer). Very sophisticated graphics capabilities. R is free software, in the sense of Richard Stallman. Two basic parts: what you get from CRAN, and then everything else. ~4000 packages developed by other users and programmers (WOW). Lots of others associated with bioconductor.org.

	- Drawbacks? 40-yr-old technology. Objects must be stored in physical memory...ooo, this might be interesting later; but support has improved in this realm recently.

	- Slide 16 is a very good reference on useful S/R books!!!

	- Ok, got swirl installed in R, and am now ready to do these exercies (run with the command 'swirl()'):

		Basic Building Blocks
		Workspace and Files
		Sequences of Numbers
		Vectors
		Missing Values
		Subsetting Vectors
		Matrices and Data Frame

	(Data types) 

	- c(x,y,...) will 'catenate' a vector, and make you a new object. An apparently important function. Types in these vectors do not have to match.

	- cool function: as.* will 'coerce' on value type/class to another.

	- lists are very important in R, and they can contain variables of different classes and types; now I'm not sure if my previous thought was true, i.e. that vectors could contain objects of differing types - we'll see.

	- matricies are special types of vectors; using the dim() function, you can assign a dimension to a vector, which will then smoosh the vector into that shape (pretty cool). There are also a couple of other functions you can use to build matricies from vectors - cbind() and rbind(), which 'bind' columns by column, or row, respectively.

	- factors are used to represent 'categorical data'; can think of it as an integer vector, where each vector has a name, or 'label.' factors have a 'levels' attribute, which is basically like the default 'sort' that will be applied to the elements that make up the list/vector - at least that's as far as I can ascertain right now.

	- missing values have a couple of tests you can apply to objects to determine if there are NAs or NANs; these are is.na() and is.nan().

	- data frames: this is a key R data type used to store tabular data. Unlike matricies, data frames don't need to store the same data type. Each row has a name: this attribute is called row.names.

	- you can name objects in R, and then refer to the elements by their names. you can also assign names to rows and columns of matricies using the dimnames() function.

	(Reading data)

	- read.table, read.csv read tabular data from files.
	- readLines will get lines from a text file.
	- write.table, writeLines
	- in read.table, the file argument can be a file, but also a 'connection'; could it be something like a real-time data stream or a database connection? Not sure yet, but am intrigued.
	- help page for read.table is very good, and very important to understand...a good resource.
	- colClasses is very important when the data set is large. When you tell R what types of data exist in the columns, R doesn't need to spend time figuring it out itself. nrows has a similar effect on memory usage. read.table will require ~2x the amount of memory to store data than is 'theoretically' required to store it.

	(Writing data)

	- dput() will output some R code that can be used to recontruct an R object - dget() has the analog effect.

	(Interfacing to outside data)

	- done through 'connections'...

	(Subsetting)

	- subsetting is the R-term used to denote picking data out of larger sets. Done with '[', '[[', and '$' ($ is for names). Indecies can be numeric, but can also be 'logical' - enabling tests to be run against elements of the list. [[]] operator can use a calculated value, like a variable, which can be very useful.

	- pattern matching seems cool, almost like 'tab completion', but a little different.

	- some good stuff on getting rid of missing values; not sure how to apply it yet.

	- vectorized operations allow you to avoid a lot of explicit looping